{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch for Computer Vision<br/>Example 2 - Fashion MNIST + VGGNET\n",
    "## TDC SP 2019 - Track: Machine Learning\n",
    "\n",
    "**After this notebook, you'll be able to:**\n",
    "- Use a PyTorch dataset for training a Neural Network\n",
    "- Use a PyTorch model for training a Neural Network\n",
    "- Make inference in new images\n",
    "\n",
    "Let's start ... Importing libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import inspect\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preparing Data\n",
    "\n",
    "- Defining a Transform Pipeline, used in Train and Test Sets\n",
    "- Download Fashion MNIST into Train and Test Sets\n",
    "- Create Loader for Train, Val and Test Sets\n",
    "- Visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform pipeline (Compose), resizing image to 224x224, transforming it in Tensor and Normalizing using mean = 0.5 and std = 0.5\n",
    "# Normalize is applied in each channel (RGB) and in the code below does: image = (image - mean) / std, normalizing the image in the range [-1,1].\n",
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.Grayscale(num_output_channels=3),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader parameters\n",
    "batch_size = 1024\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Fashion MNIST dataset (from torchvision.datasets) into trainset, passing through transform pipeline\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train = True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation split \n",
    "split = int(0.8 * len(trainset))\n",
    "index_list = list(range(len(trainset)))\n",
    "train_idx, valid_idx = index_list[:split], index_list[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create sampler objects using SubsetRandomSampler\n",
    "tr_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tr_sampler into trainloader, for using in NN training process\n",
    "trainloader = torch.utils.data.DataLoader(trainset, sampler=tr_sampler, num_workers=num_workers, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load val_sampler into valloader, for using in NN training process\n",
    "valloader = torch.utils.data.DataLoader(trainset, sampler=val_sampler, num_workers=num_workers, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Fashion MNIST dataset (from torchvision.datasets) into testset, passing through transform pipeline\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train = False, transform=transform, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testset into testloader, for using in NN validation process\n",
    "testloader = torch.utils.data.DataLoader(testset, num_workers=num_workers, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Dataset Stats\n",
    "print('# training images: ', len(tr_sampler))\n",
    "print('# validation images: ', len(val_sampler))\n",
    "print('# test images: ', len(testset))\n",
    "print('Classes: ', trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Some sample data\n",
    "\n",
    "# Obtaning first batch of training images, through iterator of DataLoader\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'};\n",
    "\n",
    "fig = plt.figure(figsize=(16,16));\n",
    "columns = 4;\n",
    "rows = 5;\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_xy = np.random.randint(len(images));\n",
    "    img = images[img_xy][0]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(str(labels_map[int(labels[img_xy])]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \"Create\" NN using VGG19 model - Transfer Learning\n",
    "\n",
    "- Import VGG19 from torchvision models\n",
    "- Freeze feature layers, avoiding training\n",
    "- Fine tune output layer (FC) to FMNIST Classes\n",
    "- Define NN hyperparameters (Loss, Optimizer, Learning Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using VGG19 from torchvision models\n",
    "vgg19 = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 19 Architecture\n",
    "\n",
    "![VGG](VGG19.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show VGG19 Architecture\n",
    "print(vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show input and output\n",
    "print(vgg19.classifier[0].in_features) \n",
    "print(vgg19.classifier[6].out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze training for all \"features\" layers\n",
    "for param in vgg19.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Input features - Output layer\n",
    "num_features_fc = vgg19.classifier[6].in_features\n",
    "\n",
    "# Num classes - Output layer\n",
    "num_outputs_fc = len(trainset.classes)\n",
    "\n",
    "# Fine tuning Output layer (FC)\n",
    "vgg19.fc = nn.Linear(num_features_fc, num_outputs_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show VGG19 Architecture\n",
    "print(vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# Loss = CrossEntropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimize only last layer with SGD (Stochastic Gradient Descent)\n",
    "optimizer_vgg19 = optim.SGD(vgg19.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay Learning Rate by a factor of 0.1 every 10 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_vgg19, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model\n",
    "\n",
    "- Get batch of images from trainloader\n",
    "- Clear Gradients\n",
    "- Forward Prop\n",
    "- Calculate Loss\n",
    "- Backward Prop (using Autograd)\n",
    "- Run Optimizer (SGD) with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric(metric_fn, true_y, pred_y):\n",
    "    # multi class problems need to have averaging method\n",
    "    if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
    "        return metric_fn(true_y, pred_y, average=\"macro\")\n",
    "    else:\n",
    "        return metric_fn(true_y, pred_y)\n",
    "    \n",
    "def print_scores(p, r, f1, a, batch_size):\n",
    "    # just an utility printing function\n",
    "    for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
    "        print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, valloader, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    start_ts = time.time()\n",
    "    \n",
    "    losses = []\n",
    "    batches = len(trainloader)\n",
    "    val_batches = len(valloader)\n",
    "    \n",
    "    # loop for every epoch (training + evaluation)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        # progress bar (works in Jupyter notebook too!)\n",
    "        progress = tqdm(enumerate(trainloader), desc=\"Loss: \", total=batches)\n",
    "\n",
    "        # ----------------- TRAINING  -------------------- \n",
    "        # set model to training\n",
    "        model.train()\n",
    "\n",
    "        for i, data in progress:\n",
    "            X, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # training step for single batch\n",
    "            model.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            scheduler.step()\n",
    "\n",
    "            # getting training quality data\n",
    "            current_loss = loss.item()\n",
    "            total_loss += current_loss\n",
    "\n",
    "            # updating progress bar\n",
    "            progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
    "\n",
    "        # releasing unnecessary memory in GPU\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # ----------------- VALIDATION  ----------------- \n",
    "        val_losses = 0\n",
    "        precision, recall, f1, accuracy = [], [], [], []\n",
    "\n",
    "        # set model to evaluating (testing)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader):\n",
    "                X, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                outputs = model(X) # this get's the prediction from the network\n",
    "\n",
    "                val_losses += criterion(outputs, y)\n",
    "\n",
    "                predicted_classes = torch.max(outputs, 1)[1] # get class from network's prediction\n",
    "\n",
    "                # calculate P/R/F1/A metrics for batch\n",
    "                for acc, metric in zip((precision, recall, f1, accuracy), \n",
    "                                       (precision_score, recall_score, f1_score, accuracy_score)):\n",
    "                    acc.append(\n",
    "                        calculate_metric(metric, y.cpu(), predicted_classes.cpu())\n",
    "                    )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
    "        print_scores(precision, recall, f1, accuracy, val_batches)\n",
    "        losses.append(total_loss/batches) # for plotting learning curve\n",
    "    print(f\"Training time: {time.time()-start_ts}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(vgg19, trainloader, valloader, criterion, optimizer_vgg19, exp_lr_scheduler, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(vgg19.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test(model, testloader):\n",
    "\n",
    "    # obtain one batch of test images\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    \n",
    "    labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "        7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'};\n",
    "    \n",
    "    # move model inputs to cuda, if GPU available\n",
    "    if train_on_gpu:\n",
    "        images = images.cuda()\n",
    "\n",
    "    # get sample outputs\n",
    "    output = model(images)\n",
    "    \n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "            \n",
    "    fig = plt.figure(figsize=(16,16));\n",
    "    columns = 2;\n",
    "    rows = 4;\n",
    "    for i in range(1, columns*rows +1):\n",
    "        img_xy = np.random.randint(len(images));\n",
    "        img = images[img_xy][0]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.title(str(labels_map[int(labels[img_xy])])+\" (\"+labels_map[preds[i-1]]+\")\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_test(vgg19, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful links that helped me build this notebook**\n",
    "\n",
    "- https://www.arunprakash.org/2018/12/cnn-fashion-mnist-dataset-pytorch.html\n",
    "- https://discuss.pytorch.org/t/understanding-transform-normalize/21730\n",
    "- https://www.pyimagesearch.com/2019/02/11/fashion-mnist-with-keras-and-deep-learning/\n",
    "- https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "- https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch\n",
    "- https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
    "- https://www.jianshu.com/p/34e2ef981f9e\n",
    "- https://solvemprobler.com/blog/2017/09/29/range-of-convolutional-neural-networks-on-fashion-mnist-dataset/\n",
    "- https://github.com/udacity/deep-learning-v2-pytorch/blob/master/transfer-learning/Transfer_Learning_Solution.ipynb\n",
    "- https://medium.com/@josh_2774/deep-learning-with-pytorch-9574e74d17ad\n",
    "- https://discuss.pytorch.org/t/how-to-modify-the-first-and-last-layer-of-pretrained-network/22597/4\n",
    "- https://zablo.net/blog/post/using-resnet-for-mnist-in-pytorch-tutorial/\n",
    "- https://www.kaggle.com/anandad/classify-fashion-mnist-with-vgg16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
