{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch for Computer Vision<br/>Example 1 - Convolutional Bebezal Network\n",
    "\n",
    "**After this notebook, you'll be able to:**\n",
    "- Use a folder with labels as subfolders as a dataset\n",
    "- Split train dataset into train, test and val datasets\n",
    "- Apply transformations in images for data augmentation\n",
    "- Create a Convolutional Neural Network\n",
    "- Train and validate your Convolutional Neural Network\n",
    "- Analyze metrics obtained in training task\n",
    "- Run inference in test dataset\n",
    "\n",
    "**TO DO**\n",
    "- Detect faces in a image, using another CNN\n",
    "- Train and validate, using only face detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start ... Importing libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import inspect\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preparing Data\n",
    "\n",
    "- Defining a Transform Pipeline\n",
    "- Use a image folder as dataset\n",
    "- Create Loader for Train, Val and Test Sets\n",
    "- Visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform pipeline (Compose)\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize(size=(99,99)),\n",
    "    transforms.RandomCrop(size=(96,96)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader parameters\n",
    "batch_size = 6\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image dataset\n",
    "train_data = datasets.ImageFolder('../dataset', transform=transform)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train, Validation and Test DataSet\n",
    "slices = (int(0.6 * len(train_data)), int(0.2 * len(train_data)), int(0.2 * len(train_data)))\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(train_data, slices)\n",
    "\n",
    "train_idx = list(range(len(train_dataset)))\n",
    "val_idx = list(range(len(val_dataset)))\n",
    "test_idx = list(range(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(val_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Loaders for Train, Validation and Test Datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Dataset Stats\n",
    "print('# training images: ', len(train_sampler))\n",
    "print('# validation images: ', len(valid_sampler))\n",
    "print('# test images: ', len(test_sampler))\n",
    "print('Classes: ', train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Some sample data\n",
    "\n",
    "# Obtaning first batch of training images, through iterator of DataLoader\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "labels_map = {0 : 'alegre', 1 : 'brabo', 2 : 'sonado'};\n",
    "\n",
    "fig = plt.figure(figsize=(8,8));\n",
    "columns = 2;\n",
    "rows = 3;\n",
    "for i in range(0, columns*rows):\n",
    "    img_xy = i\n",
    "    img = images[img_xy][0]\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.title(str(labels_map[int(labels[img_xy])]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create CNN for Facial Expression\n",
    "\n",
    "- Create model class with architecture of CNN\n",
    "- Define CNN hyperparameters (Loss, Optimizer, Learning Rate)\n",
    "\n",
    "Based on paper \"Facial Expression Recognition Research Based on Deep Learning\"<br/>Yongpei Zhu, Hongwei Fan, Kehong Yuan1\n",
    "\n",
    "Link: https://arxiv.org/pdf/1904.09737v1.pdf\n",
    "\n",
    "![CN](CNN_Paper.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BebezalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BebezalNet, self).__init__()\n",
    "        \n",
    "        # layer #1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # convolutional layer #2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # convolutional layer #3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(10 * 10 * 256, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "\n",
    "# Create a instance of BebezalNet\n",
    "model = BebezalNet()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# Loss = CrossEntropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimize with SGD (Stochastic Gradient Descent)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "# Epochs\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model\n",
    "\n",
    "- Get batch of images from Trainloader\n",
    "- Clear Gradients\n",
    "- Forward Prop\n",
    "- Calculate Loss\n",
    "- Backward Prop (using Autograd)\n",
    "- Run Optimizer (SGD) with Hyperparameters\n",
    "- Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, valloader, criterion, optimizer, num_epochs=5):\n",
    "    \n",
    "    start_ts = time.time()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    batches = len(trainloader)\n",
    "    val_batches = len(valloader)\n",
    "    \n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "        \n",
    "    # loop for every epoch (training + evaluation)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # progress bar (works in Jupyter notebook too!)\n",
    "        progress = tqdm(enumerate(trainloader), desc=\"Loss: \", total=batches)\n",
    "\n",
    "        # ----------------- TRAINING  -------------------- \n",
    "        # set model to training\n",
    "        model.train()\n",
    "        \n",
    "        train_running_corrects = 0\n",
    "        val_running_corrects = 0\n",
    "\n",
    "        for i, data in progress:\n",
    "                        \n",
    "            X, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # training step for single batch\n",
    "            model.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # getting training quality data\n",
    "            current_train_loss = loss.item()\n",
    "            total_train_loss += current_train_loss\n",
    "            \n",
    "            # convert output probabilities to predicted class\n",
    "            _, preds_tensor = torch.max(outputs, 1)\n",
    "            \n",
    "            # calculate batch train accuracy\n",
    "            current_train_accuracy = torch.sum(preds_tensor == y.data)\n",
    "            train_running_corrects += current_train_accuracy\n",
    "\n",
    "            # updating progress bar\n",
    "            progress.set_description(\"Loss: {:.4f}\".format(total_train_loss/(i+1)))\n",
    "\n",
    "        # releasing unnecessary memory in GPU\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # ----------------- VALIDATION  ----------------- \n",
    "        # set model to evaluating (testing)\n",
    "        \n",
    "        total_val_loss = 0\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader):\n",
    "                X, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                output = model(X) # this get's the prediction from the network\n",
    "\n",
    "                current_val_loss = criterion(output, y)\n",
    "                total_val_loss += current_val_loss\n",
    "                \n",
    "                # convert output probabilities to predicted class\n",
    "                _, preds_tensor = torch.max(output, 1)\n",
    "                \n",
    "                # calculate batch val accuracy\n",
    "                current_val_accuracy = torch.sum(preds_tensor == y.data)\n",
    "                val_running_corrects += current_val_accuracy\n",
    "        \n",
    "        epoch_train_acc = train_running_corrects.double() / len(train_sampler)\n",
    "        train_accuracy.append(epoch_train_acc.numpy())\n",
    "\n",
    "        epoch_val_acc = val_running_corrects.double() / len(valid_sampler)\n",
    "        val_accuracy.append(epoch_val_acc.numpy())\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, training loss: {total_train_loss/batches}, validation loss: {total_val_loss/val_batches}, training acc: {epoch_train_acc*100}, validation acc: {epoch_val_acc*100}\")\n",
    "                        \n",
    "        train_losses.append(total_train_loss/batches)\n",
    "        val_losses.append(total_val_loss/val_batches)\n",
    "        \n",
    "        # save model if validation loss has decreased\n",
    "        if current_val_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            current_val_loss))\n",
    "            torch.save(model.state_dict(), 'model.ckpt')\n",
    "            valid_loss_min = current_val_loss\n",
    "        \n",
    "    print(f\"Training time: {time.time()-start_ts}s\")\n",
    "    return np.squeeze(train_losses), np.squeeze(val_losses), np.squeeze(train_accuracy), np.squeeze(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, train_accuracy, val_accuracy = train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_metrics(train_losses, val_losses, train_accuracy, val_accuracy):\n",
    "    \n",
    "    plt.figure(figsize=(8,8));\n",
    "\n",
    "    # Create Loss plot\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(range(num_epochs), train_losses)\n",
    "    plt.plot(range(num_epochs), val_losses)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend(['train', 'val'], loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8));\n",
    "    \n",
    "    # Create Accuracy plot\n",
    "    plt.title(\"Accuracy Score\")\n",
    "    plt.plot(range(num_epochs), train_accuracy)\n",
    "    plt.plot(range(num_epochs), val_accuracy)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylim((0, 1.5))\n",
    "    plt.legend(['train', 'val'], loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_metrics(train_losses, val_losses, train_accuracy, val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test(model, testloader):\n",
    "\n",
    "    # obtain one batch of test images\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "    \n",
    "    labels_map = {0 : 'alegre', 1 : 'brabo', 2 : 'sonado'};\n",
    "\n",
    "    # move model inputs to cuda, if GPU available\n",
    "    if train_on_gpu:\n",
    "        images = images.cuda()\n",
    "\n",
    "    # get sample outputs\n",
    "    output = model(images)\n",
    "    \n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "            \n",
    "    fig = plt.figure(figsize=(8,8));\n",
    "    columns = 3;\n",
    "    rows = 2;\n",
    "    for i in range(0, columns*rows):\n",
    "        img_xy = i;\n",
    "        img = images[img_xy][0]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.title(str(labels_map[int(labels[img_xy])])+\" (\"+labels_map[preds[i]]+\")\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful links that helped me build this notebook**\n",
    "\n",
    "- https://discuss.pytorch.org/t/understanding-transform-normalize/21730\n",
    "- https://www.jianshu.com/p/34e2ef981f9e\n",
    "- https://medium.com/@josh_2774/deep-learning-with-pytorch-9574e74d17ad\n",
    "- https://hackernoon.com/binary-face-classifier-using-pytorch-2d835ccb7816\n",
    "- https://www.udacity.com/course/deep-learning-pytorch--ud188\n",
    "- https://www.udacity.com/facebook-pytorch-scholarship\n",
    "- https://github.com/udacity/deep-learning-v2-pytorch\n",
    "- https://deshanadesai.github.io/notes/PyTorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
